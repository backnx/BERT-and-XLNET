{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **1. Tổng quan bài toán**\n\n\n*   Tập dữ liệu IMDB có 50 nghìn đánh giá phim, từ đó ta để có thể tiến hành Xử lý ngôn ngữ tự nhiên hoặc Phân tích văn bản.\n*   Đây là tập dữ liệu phân lớp nhị phân, chứa nhiều dữ liệu hơn đáng kể so với tập dữ liệu chuẩn trước đó. Tập dữ liệu này cung cấp một bộ gồm 25.000 bài đánh giá phim có tính phân cực cao để đào tạo và 25.000 để thử nghiệm. \n\n*   Thông tin chi tiết về dữ liệu:\nhttp://ai.stanford.edu/~amaas/data/sentiment/\n\nỞ đây, tôi sẽ đào tạo một mô hình để dự đoán xem đánh giá phim IMDB là tích cực hay tiêu cực bằng cách sử dụng BERT trong Tensorflow với TF-Hub.\n\n\n1.   Input bài toán: IMDB Dataset of 50K Movie Reviews (Large Movie Review Dataset)\n2.   Output bài toán: Mô hình BERT dự đoán một đánh giá là tích cực hay tiêu cực.","metadata":{"id":"4gdWm4P332Wk"}},{"cell_type":"markdown","source":"# **2. Khai báo các thư viện cần thiêt**","metadata":{"id":"W92QRjWGpKGm"}},{"cell_type":"code","source":"!pip install pyspellchecker\n!pip install colorama\n!pip install simpletransformers\n!pip install transformers","metadata":{"id":"md05JNs5scAF","outputId":"d6f9ca5e-3140-4e70-837e-512923d3be7e","execution":{"iopub.status.busy":"2021-12-03T10:25:24.427486Z","iopub.execute_input":"2021-12-03T10:25:24.427747Z","iopub.status.idle":"2021-12-03T10:26:02.153326Z","shell.execute_reply.started":"2021-12-03T10:25:24.427717Z","shell.execute_reply":"2021-12-03T10:26:02.152452Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport tensorflow as tf\nfrom datetime import datetime\n\nimport os\nfrom pathlib import Path\n\nimport plotly.offline as plty\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n\nfrom wordcloud import WordCloud\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom colorama import Fore, Back, Style, init\n\nfrom tqdm import tqdm\ntqdm.pandas()\npd.set_option('display.max_colwidth', None)\n\nfrom spellchecker import SpellChecker\nimport spacy\nimport string, re\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nnltk.download('vader_lexicon')\n\nimport transformers\nimport tensorflow as tf\nfrom tokenizers import BertWordPieceTokenizer\n\nfrom tensorflow.keras.callbacks import Callback\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Input, Dropout, Embedding\nfrom tensorflow.keras.layers import LSTM, GRU, Conv1D, SpatialDropout1D\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import activations\nfrom tensorflow.keras import constraints\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras import regularizers\n\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.activations import *\nfrom tensorflow.keras.constraints import *\nfrom tensorflow.keras.initializers import *\nfrom tensorflow.keras.regularizers import *\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)","metadata":{"id":"_bRkHu0MrgHN","outputId":"19202ff7-af93-4d91-dd59-20e987c5f924","execution":{"iopub.status.busy":"2021-12-03T10:26:07.744653Z","iopub.execute_input":"2021-12-03T10:26:07.744903Z","iopub.status.idle":"2021-12-03T10:26:07.766000Z","shell.execute_reply.started":"2021-12-03T10:26:07.744870Z","shell.execute_reply":"2021-12-03T10:26:07.761879Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# **3.  Xây dựng dữ liệu**","metadata":{"id":"BekY5Mb_slSB"}},{"cell_type":"markdown","source":"## **3.1. Load dữ liệu vào DataFrame**","metadata":{"id":"ZAiIUzeN0ug0"}},{"cell_type":"markdown","source":"Tập dữ liệu gồm hai trường:\n1.   Trường \"review\" gồm các đoạn văn bản với nội dung đánh giá về một bộ phim.\n2.   Trường \"sentiment\" tương ứng là Label cho đoạn văn bản đó có nội dung Tích cực hay Tiêu cực.","metadata":{"id":"Cq4N_fBt2EDD"}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","metadata":{"id":"cpVMuj8Rr9bw","execution":{"iopub.status.busy":"2021-12-03T10:26:07.768563Z","iopub.execute_input":"2021-12-03T10:26:07.768865Z","iopub.status.idle":"2021-12-03T10:26:08.955364Z","shell.execute_reply.started":"2021-12-03T10:26:07.768820Z","shell.execute_reply":"2021-12-03T10:26:08.954602Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"id":"_Xb2S0CMs7R3","outputId":"f74e9d66-718d-4a94-cfcb-e3fd3fda676d","execution":{"iopub.status.busy":"2021-12-03T09:19:10.624530Z","iopub.execute_input":"2021-12-03T09:19:10.624750Z","iopub.status.idle":"2021-12-03T09:19:10.657394Z","shell.execute_reply.started":"2021-12-03T09:19:10.624713Z","shell.execute_reply":"2021-12-03T09:19:10.656660Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"id":"5vU6owdSvlpQ","outputId":"1691ac93-b986-4726-9f0c-25962e357c50","execution":{"iopub.status.busy":"2021-12-03T09:19:10.658690Z","iopub.execute_input":"2021-12-03T09:19:10.659128Z","iopub.status.idle":"2021-12-03T09:19:10.676313Z","shell.execute_reply.started":"2021-12-03T09:19:10.659089Z","shell.execute_reply":"2021-12-03T09:19:10.675643Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## **3.2. Tiền xử lý dữ liệu**","metadata":{"id":"DSAEns_S1vVR"}},{"cell_type":"markdown","source":"Có thể nhận thấy dữ liệu ở trường \"**sentiment**\" đang ở dạng chữ, trong khi đây là dữ liệu dạng nhị phân. Hơn thế nữa trong các bài toán Học máy, chúng ta thường đưa dữ liệu Label ở dạng này về dạng số để dễ xử lý hơn và trong bài toán này cũng vậy.\n\nVì vậy, ta sẽ Mapping trường này về dạng Numbers, với:\n\n\n*   1 thể hiện cho nhận xét Review Tích cực.\n*   0 thể hiện cho nhận xét Review Tiêu cực.\n\n","metadata":{"id":"xoOWi4K4yS3k"}},{"cell_type":"code","source":"df['sentiment'] = df['sentiment'].map({'positive' : 1, 'negative' : 0})","metadata":{"id":"a1S8eKp_5HHn","execution":{"iopub.status.busy":"2021-12-03T10:26:08.956543Z","iopub.execute_input":"2021-12-03T10:26:08.956814Z","iopub.status.idle":"2021-12-03T10:26:08.977928Z","shell.execute_reply.started":"2021-12-03T10:26:08.956768Z","shell.execute_reply":"2021-12-03T10:26:08.977028Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df[['review','sentiment']].head(5)","metadata":{"id":"YtQW40wQ5ZmI","outputId":"53e7ab34-4a8d-43f1-aba8-18c080b8f013","execution":{"iopub.status.busy":"2021-12-03T09:19:10.692400Z","iopub.execute_input":"2021-12-03T09:19:10.692860Z","iopub.status.idle":"2021-12-03T09:19:10.707734Z","shell.execute_reply.started":"2021-12-03T09:19:10.692821Z","shell.execute_reply":"2021-12-03T09:19:10.706835Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Ta có thể nhận thấy dữ liệu ở trường \"**review**\" còn khá nhiều ký hiệu `<br />` thể hiện xuống dòng trong HTML, các dấu chấm, dấu phẩy, dấu ngoặc, v.v.. rất nhiều ký tự gây nhiễu và không có giá trị trong mô hình. Các ký hiệu này có thể làm mô hình dự đoán bị sai lệch. \n\nMặt khác, các ký tự trong các đoạn văn bản đang ở dạng viết hoa và viết thường khá lộn xộn và cần đưa về một dạng thống nhất gồm toàn các từ ngữ viết thường.\n\nNgoài ra, ở đây để cẩn thận hơn, chúng ta có thể sử dụng thư viện Spell Checker để check chính tả cho dữ liệu đầu vào.","metadata":{"id":"a8Y8vVcZ64sR"}},{"cell_type":"code","source":"PUNCT_TO_REMOVE = string.punctuation\n\ndef remove_punctuation(text):    \n    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n\ndef remove_urls(text):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)\n\ndef remove_html(text):\n    html_pattern = re.compile('<.*?>')\n    return html_pattern.sub(r'', text)","metadata":{"id":"DLxJXszs_KIT","execution":{"iopub.status.busy":"2021-12-03T10:26:08.979255Z","iopub.execute_input":"2021-12-03T10:26:08.979817Z","iopub.status.idle":"2021-12-03T10:26:08.985641Z","shell.execute_reply.started":"2021-12-03T10:26:08.979778Z","shell.execute_reply":"2021-12-03T10:26:08.984599Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    \n    # Lower Casing\n    text = text.lower()\n    \n    # Remove url\n    text = remove_urls(text) \n    \n    # Remove html tags\n    text = remove_html(text)\n    \n    # Removing @tags\n    text = re.sub('@\\w*','',text)\n    \n    # Removing Punctuations\n    text = remove_punctuation(text)\n    \n    # Removing new lines\n    text = re.sub('\\\\n',' ',text)\n    \n    return text","metadata":{"id":"gNbnRLGdCahg","execution":{"iopub.status.busy":"2021-12-03T10:26:08.987207Z","iopub.execute_input":"2021-12-03T10:26:08.987701Z","iopub.status.idle":"2021-12-03T10:26:08.994828Z","shell.execute_reply.started":"2021-12-03T10:26:08.987665Z","shell.execute_reply":"2021-12-03T10:26:08.993963Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df[\"clean_text\"] = df[\"review\"].progress_apply(lambda text: clean_text(text))","metadata":{"id":"kh_jCPP6EHYC","outputId":"f00fe641-8ec8-4b37-e256-293a01539717","execution":{"iopub.status.busy":"2021-12-03T10:26:08.996409Z","iopub.execute_input":"2021-12-03T10:26:08.996952Z","iopub.status.idle":"2021-12-03T10:26:12.654234Z","shell.execute_reply.started":"2021-12-03T10:26:08.996902Z","shell.execute_reply":"2021-12-03T10:26:12.653504Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df[['review','clean_text']].head(2)","metadata":{"id":"7NF6Yfe2EeiX","outputId":"cf362569-09dd-4864-c357-6bef9f1015c0","execution":{"iopub.status.busy":"2021-12-03T09:19:13.943188Z","iopub.execute_input":"2021-12-03T09:19:13.943875Z","iopub.status.idle":"2021-12-03T09:19:13.962749Z","shell.execute_reply.started":"2021-12-03T09:19:13.943835Z","shell.execute_reply":"2021-12-03T09:19:13.961981Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## **3.3. Trực quan hoá dữ liệu**","metadata":{"id":"0bu3uHv1IPGr"}},{"cell_type":"markdown","source":"### **3.3.1. Mức độ phổ biến của các từ**","metadata":{"id":"cCqPGIKkK6gP"}},{"cell_type":"code","source":"test_string = ' '.join(df.query('sentiment == 0')['clean_text'])\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(test_string)\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Độ phổ biến của các từ trong các đánh giá Tiêu cực')","metadata":{"id":"CYZKEcuyMEUk","outputId":"09ed531f-3118-4b15-d2c5-0da9b53d6f47","execution":{"iopub.status.busy":"2021-12-03T09:19:13.964156Z","iopub.execute_input":"2021-12-03T09:19:13.964423Z","iopub.status.idle":"2021-12-03T09:19:24.003007Z","shell.execute_reply.started":"2021-12-03T09:19:13.964386Z","shell.execute_reply":"2021-12-03T09:19:24.002278Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test_string = ' '.join(df.query('sentiment == 1')['clean_text'])\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(test_string)\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Độ phổ biến của các từ trong các đánh giá Tích cực')","metadata":{"id":"NfkpvMu-Mm6c","outputId":"def42bec-aa70-4c7c-bded-ef9644e6a6cb","execution":{"iopub.status.busy":"2021-12-03T09:19:24.003996Z","iopub.execute_input":"2021-12-03T09:19:24.004231Z","iopub.status.idle":"2021-12-03T09:19:33.674046Z","shell.execute_reply.started":"2021-12-03T09:19:24.004198Z","shell.execute_reply":"2021-12-03T09:19:33.673438Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### **3.3.2. Đánh giá quan điểm trên tập dữ liệu**","metadata":{"id":"V0CfA2c8L0j7"}},{"cell_type":"markdown","source":"Ta sẽ áp dụng mô hình VADER (Valence Aware Dictionary for Sentiment Reasoning), một mô hình được sử dụng để phân tích thái cực tình cảm văn bản với cả hai cực (tích cực / tiêu cực) của cảm xúc. \n\nVADER ánh xạ các đặc điểm từ vựng với cường độ cảm xúc thành một danh sách tạm dịch là **điểm Sentiment**. \n\nVí dụ - những từ như \"love\", \"enjoy\", \"happy\", \"like\" đều thể hiện tình cảm tích cực. Ngoài ra VADER hiểu ngữ cảnh cơ bản của những từ này, chẳng hạn như \"did not love\" là một câu nói mang tính tiêu cực. Nó cũng hiểu được sự nhấn mạnh của viết hoa và dấu chấm câu, chẳng hạn như \"ENJOY\"","metadata":{"id":"J9ExBJ2uewYs"}},{"cell_type":"code","source":"def polarity(text):\n    if type(text) == str:\n        return sid.polarity_scores(text)\n    else:\n        return -1\n    \nsid = SentimentIntensityAnalyzer()\ndf[\"polarity\"] = df[\"clean_text\"].progress_apply(polarity)","metadata":{"id":"1WHtk_KudnvR","outputId":"687035e5-0e17-4e51-85d3-04ce19c64714","execution":{"iopub.status.busy":"2021-12-03T09:19:33.675248Z","iopub.execute_input":"2021-12-03T09:19:33.676013Z","iopub.status.idle":"2021-12-03T09:21:54.919835Z","shell.execute_reply.started":"2021-12-03T09:19:33.675974Z","shell.execute_reply":"2021-12-03T09:21:54.919000Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df[\"polarity\"].head()","metadata":{"id":"oA7sg7-hhDhH","outputId":"d4cdcf44-69b3-4007-b3a3-15246eb1dfaa","execution":{"iopub.status.busy":"2021-12-03T09:21:54.921453Z","iopub.execute_input":"2021-12-03T09:21:54.921722Z","iopub.status.idle":"2021-12-03T09:21:54.929144Z","shell.execute_reply.started":"2021-12-03T09:21:54.921685Z","shell.execute_reply":"2021-12-03T09:21:54.928441Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"#### 3.3.2.1. Quan điểm đánh giá tiêu cực ","metadata":{"id":"9_9QUIJT7lKG"}},{"cell_type":"code","source":"neg_pol = [pols['neg'] for pols in df[\"polarity\"] if type(pols) is dict]\nneg_pol = list(filter((0.0).__ne__, neg_pol))\n\nfig = go.Figure(go.Histogram(x=neg_pol, marker=dict(\n            color='red')\n    ))\n\nfig.update_layout(xaxis_title=\"Xu hướng\", title_text=\"Xu hướng đánh giá tiêu cực\", template=\"simple_white\")\nfig.show()","metadata":{"id":"u8r91kLUgzD2","outputId":"bc6a4850-c1e2-4d2f-d720-3285ed238bf9","execution":{"iopub.status.busy":"2021-12-03T09:21:54.930497Z","iopub.execute_input":"2021-12-03T09:21:54.931049Z","iopub.status.idle":"2021-12-03T09:21:55.409412Z","shell.execute_reply.started":"2021-12-03T09:21:54.931009Z","shell.execute_reply":"2021-12-03T09:21:55.408795Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Từ biểu đồ trên, chúng ta có thể thấy rằng xu hướng đánh giá tiêu cực trong tập dữ liệu có giá trị thấp, tập trung quanh mức điểm từ 0-0,3. Chứng tỏ dữ liệu không có những đánh giá quá tiêu cực hoặc gay gắt.","metadata":{"id":"v93DWc1X6aYZ"}},{"cell_type":"markdown","source":"#### 3.3.2.3. Quan điểm đánh giá tích cực ","metadata":{"id":"buViE9sq79xE"}},{"cell_type":"code","source":"neg_pol = [pols['pos'] for pols in df[\"polarity\"] if type(pols) is dict]\nneg_pol = list(filter((0.0).__ne__, neg_pol))\n\nfig = go.Figure(go.Histogram(x=neg_pol, marker=dict(\n            color='blue')\n    ))\n\nfig.update_layout(xaxis_title=\"Xu hướng\", title_text=\"Xu hướng đánh giá tích cực\", template=\"simple_white\")\nfig.show()","metadata":{"id":"SVuYl9io8HRF","outputId":"82335669-a601-4124-f48b-3e03991fd66e","execution":{"iopub.status.busy":"2021-12-03T09:21:55.410746Z","iopub.execute_input":"2021-12-03T09:21:55.411189Z","iopub.status.idle":"2021-12-03T09:21:55.842176Z","shell.execute_reply.started":"2021-12-03T09:21:55.411154Z","shell.execute_reply":"2021-12-03T09:21:55.841427Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Qua biểu đồ trên, kết hợp với phần 3.3.2.1, ta bước đầu rút ra nhận xét rằng hầu hết các đánh giá sẽ đều mang tính Trung lập, dựa vào mức điểm đánh giá thấp của cả Tiêu cực và Tích cực.","metadata":{"id":"qxZtu5Cr9q2R"}},{"cell_type":"markdown","source":"#### 3.3.2.2. Quan điểm đánh giá trung lập","metadata":{"id":"Aax04lJZ-SfD"}},{"cell_type":"code","source":"neg_pol = [pols['neu'] for pols in df[\"polarity\"] if type(pols) is dict]\nneg_pol = list(filter((0.0).__ne__, neg_pol))\n\nfig = go.Figure(go.Histogram(x=neg_pol, marker=dict(\n            color='orange')\n    ))\n\nfig.update_layout(xaxis_title=\"Xu hướng\", title_text=\"Xu hướng đánh giá trung lập\", template=\"simple_white\")\nfig.show()","metadata":{"id":"QXVTpsFt-Xba","outputId":"36981494-d4b8-4bd2-de09-0f9b101e95e3","execution":{"iopub.status.busy":"2021-12-03T09:21:55.843636Z","iopub.execute_input":"2021-12-03T09:21:55.843888Z","iopub.status.idle":"2021-12-03T09:21:56.281947Z","shell.execute_reply.started":"2021-12-03T09:21:55.843856Z","shell.execute_reply":"2021-12-03T09:21:56.281345Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Từ biểu đồ trên, chúng ta có thể thấy rằng sự phân bố đánh giá trung lập của tập dữ liệu có xu hướng lớn, tập trung chủ yếu từ điểm số 0.7-0.8. Điều này cho thấy rằng các nhận xét có xu hướng rất trung lập và không thiên vị. Đồng thời, dựa vào biểu đồ cũng cho thấy rằng hầu hết các bình luận không có tính quan điểm cá nhân cao và phân cực, có nghĩa là hầu hết các bình luận đều là dữ liệu tốt cho quá trình huấn luyện mô hình.","metadata":{"id":"O4SAO7ZJ_BAN"}},{"cell_type":"markdown","source":"### **3.3.3. Độ cân bằng dữ liệu**","metadata":{"id":"0Ls-DMqEVBbm"}},{"cell_type":"code","source":"total_comments = df['sentiment'].count()\nneg = df['sentiment'].value_counts().loc[1]\nSentiment = ['Tiêu cực','Tích cực']\ncount = [neg, total_comments-neg]\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\nfig.add_trace(go.Bar(x=Sentiment,y=count,text=count, marker_color=['#FF3333', '#0000FF']),\n             row=1, col=1)\n\nfig.add_trace(go.Pie(labels=Sentiment, values=count, domain=dict(x=[0.5, 1.0]), marker_colors=['#FF3333', '#0000FF']), \n              row=1, col=2)\n\nfig.update_layout(height=600, width=800, title_text=\"Đánh giá tích cực và tiêu cực\", template='plotly_white')\nfig.show()","metadata":{"id":"BYHjT5wiDh2E","outputId":"1372c834-3712-4e49-f144-b9a0c4ddc3bb","execution":{"iopub.status.busy":"2021-12-03T09:21:56.283004Z","iopub.execute_input":"2021-12-03T09:21:56.283368Z","iopub.status.idle":"2021-12-03T09:21:56.346658Z","shell.execute_reply.started":"2021-12-03T09:21:56.283337Z","shell.execute_reply":"2021-12-03T09:21:56.345890Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Các ý kiến về đánh giá Tích cực và Tiêu cực có sự cân đối: 25000 ý kiến tích cực và 25000 ý kiến tiêu cực - với tỉ lệ 50-50, không hề có sự mất cân bằng dữ liệu.","metadata":{"id":"twrqvB4fFL3f"}},{"cell_type":"markdown","source":"## **3.4. Phân chia tập dữ liệu**","metadata":{"id":"0iL3sCJhNjhu"}},{"cell_type":"code","source":"df = df.drop('review', 1)\ndf.rename(columns = {'clean_text':'review'}, inplace = True)","metadata":{"id":"zyMZGviNNfTt","execution":{"iopub.status.busy":"2021-12-03T10:26:12.655428Z","iopub.execute_input":"2021-12-03T10:26:12.655935Z","iopub.status.idle":"2021-12-03T10:26:12.674485Z","shell.execute_reply.started":"2021-12-03T10:26:12.655895Z","shell.execute_reply":"2021-12-03T10:26:12.673749Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\nsave_path = '/distilbert_base_uncased/'\nif not os.path.exists(save_path):\n    os.makedirs(save_path)\ntokenizer.save_pretrained(save_path)","metadata":{"id":"HjEP6S1rPOBs","outputId":"b27fa0e3-4451-48f4-fe3a-c03b5ad10ca4","execution":{"iopub.status.busy":"2021-12-03T09:21:56.364144Z","iopub.execute_input":"2021-12-03T09:21:56.364764Z","iopub.status.idle":"2021-12-03T09:21:58.197916Z","shell.execute_reply.started":"2021-12-03T09:21:56.364726Z","shell.execute_reply":"2021-12-03T09:21:58.197216Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"Ta phân chia tập dữ liệu thành các bộ: Traning Set, Validation Set và Test Set theo tỉ lệ 8 : 0.4 : 1.6","metadata":{"id":"f1kgDXHhJPr2"}},{"cell_type":"code","source":"X, y = df['review'].values,df['sentiment'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=100)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.2, stratify=y_test, random_state=100)","metadata":{"id":"dxHdGfmMTIuq","execution":{"iopub.status.busy":"2021-12-03T10:26:12.676802Z","iopub.execute_input":"2021-12-03T10:26:12.677070Z","iopub.status.idle":"2021-12-03T10:26:12.725810Z","shell.execute_reply.started":"2021-12-03T10:26:12.677034Z","shell.execute_reply":"2021-12-03T10:26:12.725086Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X_train_tokens = tokenizer(list(X_train), padding='max_length', truncation=True, return_tensors=\"tf\")\nX_train_token_ids = X_train_tokens['input_ids']\n\nX_test_tokens = tokenizer(list(X_test), padding='max_length', truncation=True, return_tensors=\"tf\")\nX_test_token_ids = X_test_tokens['input_ids']\n\nX_val_tokens = tokenizer(list(X_val), padding='max_length', truncation=True, return_tensors=\"tf\")\nX_val_token_ids = X_val_tokens['input_ids']","metadata":{"id":"MH5DYeNKahT8","execution":{"iopub.status.busy":"2021-12-03T09:21:58.250600Z","iopub.execute_input":"2021-12-03T09:21:58.250983Z","iopub.status.idle":"2021-12-03T09:22:44.620306Z","shell.execute_reply.started":"2021-12-03T09:21:58.250844Z","shell.execute_reply":"2021-12-03T09:22:44.619501Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(X_test_token_ids.shape)\nprint(X_train_token_ids.shape)","metadata":{"id":"nq0wVe8kCuP5","outputId":"d4f33f60-5ef8-4947-ec9b-2df467871760","execution":{"iopub.status.busy":"2021-12-03T09:22:44.623462Z","iopub.execute_input":"2021-12-03T09:22:44.623677Z","iopub.status.idle":"2021-12-03T09:22:44.627671Z","shell.execute_reply.started":"2021-12-03T09:22:44.623650Z","shell.execute_reply":"2021-12-03T09:22:44.626994Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# **4.  Mô hình**","metadata":{"id":"sxTFs-Mh3k9O"}},{"cell_type":"code","source":"transformer = transformers.TFDistilBertModel.\\\n    from_pretrained('distilbert-base-uncased')\nembed = transformer.weights[0].numpy()\n\nprint('Vocab : ', np.shape(embed)[0], 'Hidden States/Embed vector size :', np.shape(embed)[1])","metadata":{"id":"oGvIlYskDKhB","outputId":"3fc6e7aa-1c17-402a-f2b5-5a0eee056abe","execution":{"iopub.status.busy":"2021-12-03T09:22:44.628678Z","iopub.execute_input":"2021-12-03T09:22:44.629132Z","iopub.status.idle":"2021-12-03T09:22:54.577356Z","shell.execute_reply.started":"2021-12-03T09:22:44.629079Z","shell.execute_reply":"2021-12-03T09:22:54.576606Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512\nBATCH_SIZE = 12\nSTEPS_PER_EPOCH = X_train_token_ids.shape[0] // BATCH_SIZE","metadata":{"id":"LLIe1oYdpiVJ","execution":{"iopub.status.busy":"2021-12-03T09:22:54.578528Z","iopub.execute_input":"2021-12-03T09:22:54.578782Z","iopub.status.idle":"2021-12-03T09:22:54.583290Z","shell.execute_reply.started":"2021-12-03T09:22:54.578747Z","shell.execute_reply":"2021-12-03T09:22:54.582578Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss',  \n                                    factor=0.3, patience=2, \n                                    verbose=1, mode='auto', \n                                    epsilon=0.0001, cooldown=1, min_lr=0.000001)","metadata":{"id":"wGCnMlZgtkRg","execution":{"iopub.status.busy":"2021-12-03T09:22:54.584413Z","iopub.execute_input":"2021-12-03T09:22:54.585119Z","iopub.status.idle":"2021-12-03T09:22:54.593891Z","shell.execute_reply.started":"2021-12-03T09:22:54.585082Z","shell.execute_reply":"2021-12-03T09:22:54.593162Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## **4.1. BERT**","metadata":{"id":"Much1s1zEau2"}},{"cell_type":"code","source":"bert_transformer = transformers.TFDistilBertModel.\\\n    from_pretrained('distilbert-base-uncased')","metadata":{"id":"ieJz2u5-evir","outputId":"b3393b49-a7bc-4b6a-959e-b28a4c317f4d","execution":{"iopub.status.busy":"2021-12-03T09:22:54.598800Z","iopub.execute_input":"2021-12-03T09:22:54.599182Z","iopub.status.idle":"2021-12-03T09:22:55.341691Z","shell.execute_reply.started":"2021-12-03T09:22:54.599154Z","shell.execute_reply":"2021-12-03T09:22:55.340991Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"y_train = y_train.astype('int32')\ny_test = y_test.astype('int32')\ny_val = y_val.astype('int32')","metadata":{"id":"BTqORTLTe4xX","execution":{"iopub.status.busy":"2021-12-03T09:22:55.343040Z","iopub.execute_input":"2021-12-03T09:22:55.343497Z","iopub.status.idle":"2021-12-03T09:22:55.348725Z","shell.execute_reply.started":"2021-12-03T09:22:55.343455Z","shell.execute_reply":"2021-12-03T09:22:55.347590Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def build_bert_model(maxlen=MAX_LEN):\n    tf.autograph.experimental.do_not_convert(func=None)\n    input_ids = Input(shape=(maxlen,), dtype=tf.int32, name=\"input_word_ids\")\n    embeddings = bert_transformer(input_ids)[0]\n\n    cls_token = embeddings[:, 0, :]\n    x = Dense(maxlen, activation=\"relu\")(cls_token)\n    x = Dropout(0.5)(x)\n    out = Dense(1, activation='sigmoid')(x)\n\n    model = Model(inputs=input_ids, outputs=out)\n\n    model.compile(Adam(learning_rate=1.5e-5), \n                      loss='binary_crossentropy', \n                      metrics=['accuracy'])\n    \n    return model","metadata":{"id":"72TLtxG6e7cx","execution":{"iopub.status.busy":"2021-12-03T09:22:55.350167Z","iopub.execute_input":"2021-12-03T09:22:55.350439Z","iopub.status.idle":"2021-12-03T09:22:55.358881Z","shell.execute_reply.started":"2021-12-03T09:22:55.350401Z","shell.execute_reply":"2021-12-03T09:22:55.358122Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model = build_bert_model()\n\ntrain_history = model.fit(\n    X_train_token_ids, y_train,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=(X_val_token_ids, y_val),\n    epochs=2\n)","metadata":{"id":"J_xnN1GVe-OG","outputId":"69101806-0ca4-4661-953c-1c1d50a5b862","execution":{"iopub.status.busy":"2021-12-03T09:22:55.359965Z","iopub.execute_input":"2021-12-03T09:22:55.360604Z","iopub.status.idle":"2021-12-03T10:08:28.507245Z","shell.execute_reply.started":"2021-12-03T09:22:55.360563Z","shell.execute_reply":"2021-12-03T10:08:28.506489Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test_token_ids)","metadata":{"id":"YGDuXFH2fFFH","execution":{"iopub.status.busy":"2021-12-03T10:08:28.508952Z","iopub.execute_input":"2021-12-03T10:08:28.509195Z","iopub.status.idle":"2021-12-03T10:09:43.146697Z","shell.execute_reply.started":"2021-12-03T10:08:28.509162Z","shell.execute_reply":"2021-12-03T10:09:43.145981Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"y_pred = y_pred.reshape(y_pred.shape[0])\ny_pred","metadata":{"id":"0lIcqx7A3MtQ","outputId":"5feacde9-13e5-445f-9f28-69c93ef26a59","execution":{"iopub.status.busy":"2021-12-03T10:09:43.148184Z","iopub.execute_input":"2021-12-03T10:09:43.148429Z","iopub.status.idle":"2021-12-03T10:09:43.153538Z","shell.execute_reply.started":"2021-12-03T10:09:43.148396Z","shell.execute_reply":"2021-12-03T10:09:43.152848Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"Ở đây ta chọn Threshold cho việc dự đoán Review là tích cực hay tiêu cực là 0.5: \n\n*   y_preds > 0.5 tương đương với 1\n*   y_preds < 0.5 tương đương với 0\n\n","metadata":{"id":"zPqwwha6B94U"}},{"cell_type":"code","source":"y_preds = y_pred > 0.5\ny_preds = np.where(y_preds == True, 1, 0)","metadata":{"id":"cZBahXrBoFh_","execution":{"iopub.status.busy":"2021-12-03T10:09:43.154731Z","iopub.execute_input":"2021-12-03T10:09:43.155192Z","iopub.status.idle":"2021-12-03T10:09:43.164784Z","shell.execute_reply.started":"2021-12-03T10:09:43.155156Z","shell.execute_reply":"2021-12-03T10:09:43.164040Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_preds, y_test)\naccuracy","metadata":{"id":"LF1mXpUqoGGH","outputId":"4d5da9c8-0bd0-4636-d996-f930803b42a2","execution":{"iopub.status.busy":"2021-12-03T10:09:43.166077Z","iopub.execute_input":"2021-12-03T10:09:43.166517Z","iopub.status.idle":"2021-12-03T10:09:43.177619Z","shell.execute_reply.started":"2021-12-03T10:09:43.166483Z","shell.execute_reply":"2021-12-03T10:09:43.176975Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## **4.2. XLNet**","metadata":{"id":"AEagLGs7_WEV"}},{"cell_type":"code","source":"train_df = pd.DataFrame({ 'text': list(X_train),'label': y_train,}, columns=['text','label'])","metadata":{"id":"HAOpHXzb_OeY","execution":{"iopub.status.busy":"2021-12-03T10:26:12.727247Z","iopub.execute_input":"2021-12-03T10:26:12.727499Z","iopub.status.idle":"2021-12-03T10:26:12.747133Z","shell.execute_reply.started":"2021-12-03T10:26:12.727466Z","shell.execute_reply":"2021-12-03T10:26:12.746353Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_df = pd.DataFrame({ 'text': list(X_test),'label': y_test,}, columns=['text','label'])","metadata":{"id":"QlPXiKTcAf9h","execution":{"iopub.status.busy":"2021-12-03T10:26:12.748498Z","iopub.execute_input":"2021-12-03T10:26:12.748998Z","iopub.status.idle":"2021-12-03T10:26:12.759041Z","shell.execute_reply.started":"2021-12-03T10:26:12.748947Z","shell.execute_reply":"2021-12-03T10:26:12.758208Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"id":"AY6fafROBkE2","outputId":"c422246f-b8c3-48b8-c08f-50eee2d39ceb","execution":{"iopub.status.busy":"2021-12-03T10:09:43.216163Z","iopub.execute_input":"2021-12-03T10:09:43.217063Z","iopub.status.idle":"2021-12-03T10:09:43.237226Z","shell.execute_reply.started":"2021-12-03T10:09:43.217001Z","shell.execute_reply":"2021-12-03T10:09:43.236579Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"train_args = {\n    'reprocess_input_data': True,\n    'overwrite_output_dir': True,\n    'sliding_window': True,\n    'max_seq_length': 64,\n    'num_train_epochs': 1,\n    'learning_rate': 0.00001,\n    'weight_decay': 0.01,\n    'train_batch_size': 128,\n    'fp16': True,\n    'use_cuda': True,\n    'output_dir': '/outputs/',\n}","metadata":{"id":"aYwkbR403DKv","execution":{"iopub.status.busy":"2021-12-03T10:26:38.507849Z","iopub.execute_input":"2021-12-03T10:26:38.508600Z","iopub.status.idle":"2021-12-03T10:26:38.515237Z","shell.execute_reply.started":"2021-12-03T10:26:38.508563Z","shell.execute_reply":"2021-12-03T10:26:38.513275Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from simpletransformers.classification import ClassificationModel\nimport logging\nimport sklearn\n\nlogging.basicConfig(level=logging.DEBUG)\ntransformers_logger = logging.getLogger('transformers')\ntransformers_logger.setLevel(logging.WARNING)\n\n# We use the XLNet base cased pre-trained model.\nmodel_xlnet = ClassificationModel('xlnet', 'xlnet-base-cased', num_labels=2, args=train_args) \n\n# Train the model, there is no development or validation set for this dataset \nmodel_xlnet.train_model(train_df)\n\n# Evaluate the model in terms of accuracy score\nresult, model_outputs, wrong_predictions = model_xlnet.eval_model(test_df, acc=sklearn.metrics.accuracy_score)","metadata":{"id":"E6XW3OOB3GAb","execution":{"iopub.status.busy":"2021-12-03T10:26:42.155461Z","iopub.execute_input":"2021-12-03T10:26:42.156032Z","iopub.status.idle":"2021-12-03T11:02:01.164057Z","shell.execute_reply.started":"2021-12-03T10:26:42.155960Z","shell.execute_reply":"2021-12-03T11:02:01.163156Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"result","metadata":{"execution":{"iopub.status.busy":"2021-12-03T11:26:17.934817Z","iopub.execute_input":"2021-12-03T11:26:17.935401Z","iopub.status.idle":"2021-12-03T11:26:18.018991Z","shell.execute_reply.started":"2021-12-03T11:26:17.935300Z","shell.execute_reply":"2021-12-03T11:26:18.017733Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# **5.  Kết quả thực nghiệm mô hình**","metadata":{"id":"nmtNRRA433bp"}},{"cell_type":"markdown","source":"## **5.1. BERT**","metadata":{"id":"vnGbtkPHqf3u"}},{"cell_type":"code","source":"samples = ['This movie was amazingly brilliant.','This movie was amazingly awful.','Maybe they should try to get a better cast next time.','Only the first half of the movie was enjoyable','They could have spent the money better helping people']","metadata":{"id":"B-A5JsEGkdYY","execution":{"iopub.status.busy":"2021-12-03T10:20:41.991429Z","iopub.execute_input":"2021-12-03T10:20:41.991714Z","iopub.status.idle":"2021-12-03T10:20:41.996031Z","shell.execute_reply.started":"2021-12-03T10:20:41.991685Z","shell.execute_reply":"2021-12-03T10:20:41.994865Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def visualize_model_preds(y_pred, indices=[0, 1, 2, 3]):\n\n    for idx, i in enumerate(indices):\n        if y_test[i] == 0:\n            label = \"Non-toxic\"\n            color = f'{Fore.GREEN}'\n            symbol = '\\u2714'\n        else:\n            label = \"Toxic\"\n            color = f'{Fore.RED}'\n            symbol = '\\u2716'\n\n        print('{}{} {}'.format(color, str(idx+1) + \". \" + label, symbol))\n        print(f'{Style.RESET_ALL}')\n\n        print(X_test[idx]); print(\"\")\n        fig = go.Figure()\n        if y_test[i] == 1:\n            yl = [1 - y_pred[i], y_pred[i]]\n            \n        else:\n            yl = [1 - y_pred[i], y_pred[i]]\n\n        fig.add_trace(go.Bar(x=['Positive', 'Negative'], y=yl, marker=dict(color=[\"seagreen\", \"indianred\"])))\n        fig.update_traces(name=X_test[idx])\n        fig.update_layout(xaxis_title=\"Labels\", yaxis_title=\"Probability\", template=\"plotly_white\", title_text=\"Predictions for validation comment #{}\".format(idx+1))\n        fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-03T10:21:48.383316Z","iopub.execute_input":"2021-12-03T10:21:48.383577Z","iopub.status.idle":"2021-12-03T10:21:48.393548Z","shell.execute_reply.started":"2021-12-03T10:21:48.383548Z","shell.execute_reply":"2021-12-03T10:21:48.392877Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test_token_ids)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **5.2. XLNet**","metadata":{"id":"dgrei5ocjAMc"}},{"cell_type":"code","source":"samples = ['This movie was amazingly brilliant.','This movie was amazingly awful.','Maybe they should try to get a better cast next time.','Only the first half of the movie was enjoyable','They could have spent the money better helping people']\npredictions, _ = model_xlnet.predict(samples)\nlabel_dict = {0: 'negative', 1: 'positive'}\nfor idx, sample in enumerate(samples):\n    print('{} - {}: {}'.format(idx, label_dict[predictions[idx]], sample))","metadata":{"id":"PVOUVmRDkjwR","execution":{"iopub.status.busy":"2021-12-03T11:02:30.624945Z","iopub.execute_input":"2021-12-03T11:02:30.625678Z","iopub.status.idle":"2021-12-03T11:02:30.986808Z","shell.execute_reply.started":"2021-12-03T11:02:30.625643Z","shell.execute_reply":"2021-12-03T11:02:30.985962Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# **6.  Kết luận**","metadata":{"id":"8Zbzj4ZD38PK"}},{"cell_type":"markdown","source":"* Trong xử lý ngôn ngữ tự nhiên, việc tiền xử lý dữ liệu, Vector hoá được dữ liệu về dạng thích hợp là quan trọng để có thể áp dụng các mô hình Học máy.\n* BERT là một mô hình khá tối ưu, nhưng hạn chế của khi chạy các mô hình NLP là dữ liệu còn tương đối hạn chế và thiếu sự đa dạng. Việc đảm bảo dữ liệu có sự cân bằng, chính xác cũng là một vấn đề đáng lưu ý.\n* XLNet là một mô hình cải tiến từ BERT, nó cho thấy khả năng Training nhanh hơn, thậm chí là không cần chia Epoch nhưng vẫn cho kết quả gần như tương đương so với BERT.\n","metadata":{"id":"VeCJ9slRyoKI"}},{"cell_type":"code","source":"","metadata":{"id":"vp8MVCVeizRu"},"execution_count":null,"outputs":[]}]}